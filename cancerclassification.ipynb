{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObpxfEHe1SgT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vobpLjhg1yx-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('cancerclassification.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BQlgLIc17j1",
        "outputId": "c62d6cd3-3011-4646-c160-ceeb64e74a7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gLjGRVa2Wrh"
      },
      "outputs": [],
      "source": [
        "df.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZohjesJA2cDI"
      },
      "outputs": [],
      "source": [
        "df = df.drop('Unnamed: 32'  , axis = 1)\n",
        "df = df.drop('id' , axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ti3CFYu8jjcD"
      },
      "outputs": [],
      "source": [
        "def fun(ch):\n",
        "  if(ch == 'B'):\n",
        "    return 0 \n",
        "  else :\n",
        "    return 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_o3PI1FjUnd"
      },
      "outputs": [],
      "source": [
        "df['diagnosis'] = df.diagnosis.apply(fun)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiU7GjLsb27X"
      },
      "outputs": [],
      "source": [
        "X = df.drop('diagnosis' , axis = 1).values\n",
        "y = df['diagnosis'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpk8XjUDcoWB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsxr32I5c4R3"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkzIbFUCdEYB"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAemdB2ddV9U"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hCZyPgrdYF8",
        "outputId": "93806d5a-64b8-48a9-d508-ee829b784f48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scaler.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpvbvU0Hdajj"
      },
      "outputs": [],
      "source": [
        "X_train = scaler.transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa_tyXFWdg0b"
      },
      "outputs": [],
      "source": [
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WX5WIxddmvu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3guLcojUdpdH",
        "outputId": "53ec1e69-05e1-4a44-c598-f84d520137f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(426, 30)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-TuM6dzjJ_E",
        "outputId": "42a4fd09-ffda-4e74-ca33-345d0e540b4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 0])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMlJcVB0eBmW"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(30,activation = 'relu'))\n",
        "model.add(Dense(15,activation = 'relu'))\n",
        "model.add(Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy' , optimizer = 'adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lJZZUkVgWtr",
        "outputId": "b65815c9-ec88-4ea5-f21b-fb6f7322998a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "14/14 [==============================] - 1s 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 51/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 52/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 53/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 54/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 55/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 56/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 57/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 58/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 59/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 60/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 61/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 62/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 63/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 64/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 65/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 66/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 67/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 68/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 69/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 70/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 71/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 72/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 73/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 74/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 75/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 76/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 77/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 78/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 79/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 80/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 81/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 82/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 83/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 84/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 85/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 86/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 87/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 88/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 89/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 90/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 91/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 92/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 93/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 94/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 95/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 96/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 97/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 98/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 99/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 100/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 101/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 102/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 103/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 104/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 105/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 106/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 107/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 108/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 109/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 110/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 111/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 112/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 113/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 114/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 115/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 116/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 117/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 118/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 119/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 120/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 121/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 122/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 123/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 124/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 125/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 126/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 127/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 128/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 129/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 130/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 131/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 132/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 133/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 134/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 135/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 136/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 137/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 138/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 139/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 140/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 141/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 142/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 143/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 144/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 145/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 146/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 147/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 148/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 149/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 150/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 151/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 152/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 153/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 154/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 155/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 156/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 157/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 158/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 159/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 160/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 161/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 162/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 163/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 164/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 165/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 166/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 167/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 168/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 169/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 170/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 171/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 172/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 173/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 174/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 175/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 176/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 177/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 178/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 179/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 180/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 181/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 182/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 183/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 184/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 185/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 186/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 187/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 188/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 189/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 190/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 191/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 192/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 193/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 194/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 195/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 196/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 197/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 198/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 199/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 200/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 201/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 202/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 203/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 204/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 205/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 206/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 207/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 208/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 209/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 210/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 211/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 212/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 213/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 214/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 215/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 216/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 217/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 218/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 219/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 220/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 221/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 222/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 223/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 224/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 225/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 226/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 227/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 228/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 229/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 230/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 231/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 232/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 233/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 234/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 235/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 236/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 237/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 238/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 239/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 240/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 241/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 242/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 243/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 244/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 245/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 246/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 247/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 248/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 249/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 250/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 251/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 252/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 253/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 254/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 255/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 256/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 257/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 258/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 259/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 260/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 261/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 262/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 263/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 264/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 265/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 266/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 267/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 268/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 269/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 270/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 271/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 272/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 273/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 274/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 275/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 276/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 277/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 278/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 279/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 280/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 281/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 282/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 283/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 284/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 285/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 286/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 287/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 288/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 289/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 290/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 291/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 292/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 293/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 294/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 295/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 296/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 297/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 298/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 299/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 300/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 301/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 302/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 303/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 304/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 305/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 306/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 307/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 308/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 309/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 310/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 311/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 312/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 313/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 314/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 315/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 316/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 317/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 318/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 319/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 320/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 321/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 322/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 323/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 324/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 325/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 326/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 327/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 328/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 329/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 330/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 331/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 332/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 333/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 334/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 335/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 336/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 337/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 338/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 339/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 340/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 341/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 342/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 343/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 344/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 345/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 346/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 347/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 348/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 349/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 350/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 351/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 352/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 353/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 354/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 355/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 356/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 357/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 358/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 359/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 360/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 361/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 362/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 363/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 364/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 365/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 366/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 367/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 368/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 369/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 370/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 371/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 372/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 373/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 374/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 375/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 376/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 377/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 378/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 379/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 380/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 381/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 382/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 383/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 384/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 385/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 386/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 387/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 388/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 389/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 390/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 391/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 392/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 393/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 394/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 395/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 396/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 397/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 398/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 399/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 400/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 401/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 402/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 403/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 404/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 405/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 406/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 407/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 408/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 409/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 410/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 411/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 412/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 413/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 414/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 415/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 416/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 417/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 418/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 419/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 420/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 421/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 422/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 423/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 424/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 425/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 426/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 427/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 428/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 429/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 430/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 431/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 432/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 433/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 434/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 435/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 436/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 437/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 438/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 439/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 440/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 441/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 442/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 443/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 444/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 445/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 446/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 447/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 448/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 449/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 450/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 451/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 452/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 453/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 454/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 455/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 456/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 457/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 458/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 459/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 460/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 461/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 462/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 463/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 464/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 465/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 466/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 467/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 468/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 469/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 470/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 471/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 472/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 473/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 474/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 475/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 476/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 477/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 478/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 479/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 480/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 481/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 482/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 483/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 484/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 485/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 486/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 487/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 488/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 489/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 490/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 491/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 492/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 493/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 494/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 495/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 496/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 497/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 498/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 499/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 500/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 501/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 502/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 503/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 504/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 505/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 506/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 507/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 508/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 509/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 510/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 511/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 512/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 513/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 514/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 515/600\n",
            "14/14 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 516/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 517/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 518/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 519/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 520/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 521/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 522/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 523/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 524/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 525/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 526/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 527/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 528/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 529/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 530/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 531/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 532/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 533/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 534/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 535/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 536/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 537/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 538/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 539/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 540/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 541/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 542/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 543/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 544/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 545/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 546/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 547/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 548/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 549/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 550/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 551/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 552/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 553/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 554/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 555/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 556/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 557/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 558/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 559/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 560/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 561/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 562/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 563/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 564/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 565/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 566/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 567/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 568/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 569/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 570/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 571/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 572/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 573/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 574/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 575/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 576/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 577/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 578/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 579/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 580/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 581/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 582/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 583/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 584/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 585/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 586/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 587/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 588/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 589/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 590/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 591/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 592/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 593/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 594/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 595/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 596/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 597/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 598/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 599/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 600/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f22dc73db50>"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train , y_train , epochs = 600 , validation_data = (X_test , y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "aE6r9MOKmCkr",
        "outputId": "3a247e8c-0a50-49cc-82cf-ef3606affe6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f22dc867310>"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "losses.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB2kwG7pmKZa"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(30,activation = 'relu'))\n",
        "model.add(Dense(15,activation = 'relu'))\n",
        "model.add(Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy' , optimizer = 'adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K7jaGk2n1hx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import  EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-K5E6nIoCHn",
        "outputId": "7381882e-c78b-4436-86a9-c53ea96fcf9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class EarlyStopping in module keras.callbacks:\n",
            "\n",
            "class EarlyStopping(Callback)\n",
            " |  EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
            " |  \n",
            " |  Stop training when a monitored metric has stopped improving.\n",
            " |  \n",
            " |  Assuming the goal of a training is to minimize the loss. With this, the\n",
            " |  metric to be monitored would be `'loss'`, and mode would be `'min'`. A\n",
            " |  `model.fit()` training loop will check at end of every epoch whether\n",
            " |  the loss is no longer decreasing, considering the `min_delta` and\n",
            " |  `patience` if applicable. Once it's found no longer decreasing,\n",
            " |  `model.stop_training` is marked True and the training terminates.\n",
            " |  \n",
            " |  The quantity to be monitored needs to be available in `logs` dict.\n",
            " |  To make it so, pass the loss or metrics at `model.compile()`.\n",
            " |  \n",
            " |  Args:\n",
            " |    monitor: Quantity to be monitored.\n",
            " |    min_delta: Minimum change in the monitored quantity\n",
            " |        to qualify as an improvement, i.e. an absolute\n",
            " |        change of less than min_delta, will count as no\n",
            " |        improvement.\n",
            " |    patience: Number of epochs with no improvement\n",
            " |        after which training will be stopped.\n",
            " |    verbose: verbosity mode.\n",
            " |    mode: One of `{\"auto\", \"min\", \"max\"}`. In `min` mode,\n",
            " |        training will stop when the quantity\n",
            " |        monitored has stopped decreasing; in `\"max\"`\n",
            " |        mode it will stop when the quantity\n",
            " |        monitored has stopped increasing; in `\"auto\"`\n",
            " |        mode, the direction is automatically inferred\n",
            " |        from the name of the monitored quantity.\n",
            " |    baseline: Baseline value for the monitored quantity.\n",
            " |        Training will stop if the model doesn't show improvement over the\n",
            " |        baseline.\n",
            " |    restore_best_weights: Whether to restore model weights from\n",
            " |        the epoch with the best value of the monitored quantity.\n",
            " |        If False, the model weights obtained at the last step of\n",
            " |        training are used. An epoch will be restored regardless\n",
            " |        of the performance relative to the `baseline`. If no epoch\n",
            " |        improves on `baseline`, training will run for `patience`\n",
            " |        epochs and restore weights from the best epoch in that set.\n",
            " |  \n",
            " |  Example:\n",
            " |  \n",
            " |  >>> callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
            " |  >>> # This callback will stop the training when there is no improvement in\n",
            " |  >>> # the loss for three consecutive epochs.\n",
            " |  >>> model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n",
            " |  >>> model.compile(tf.keras.optimizers.SGD(), loss='mse')\n",
            " |  >>> history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),\n",
            " |  ...                     epochs=10, batch_size=1, callbacks=[callback],\n",
            " |  ...                     verbose=0)\n",
            " |  >>> len(history.history['loss'])  # Only 4 epochs are run.\n",
            " |  4\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      EarlyStopping\n",
            " |      Callback\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  get_monitor_value(self, logs)\n",
            " |  \n",
            " |  on_epoch_end(self, epoch, logs=None)\n",
            " |      Called at the end of an epoch.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run. This function should only\n",
            " |      be called during TRAIN mode.\n",
            " |      \n",
            " |      Args:\n",
            " |          epoch: Integer, index of epoch.\n",
            " |          logs: Dict, metric results for this training epoch, and for the\n",
            " |            validation epoch if validation is performed. Validation result keys\n",
            " |            are prefixed with `val_`. For training epoch, the values of the\n",
            " |           `Model`'s metrics are returned. Example : `{'loss': 0.2, 'accuracy':\n",
            " |             0.7}`.\n",
            " |  \n",
            " |  on_train_begin(self, logs=None)\n",
            " |      Called at the beginning of training.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Args:\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_train_end(self, logs=None)\n",
            " |      Called at the end of training.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Args:\n",
            " |          logs: Dict. Currently the output of the last call to `on_epoch_end()`\n",
            " |            is passed to this argument for this method but that may change in\n",
            " |            the future.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from Callback:\n",
            " |  \n",
            " |  on_batch_begin(self, batch, logs=None)\n",
            " |      A backwards compatibility alias for `on_train_batch_begin`.\n",
            " |  \n",
            " |  on_batch_end(self, batch, logs=None)\n",
            " |      A backwards compatibility alias for `on_train_batch_end`.\n",
            " |  \n",
            " |  on_epoch_begin(self, epoch, logs=None)\n",
            " |      Called at the start of an epoch.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run. This function should only\n",
            " |      be called during TRAIN mode.\n",
            " |      \n",
            " |      Args:\n",
            " |          epoch: Integer, index of epoch.\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_predict_batch_begin(self, batch, logs=None)\n",
            " |      Called at the beginning of a batch in `predict` methods.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Note that if the `steps_per_execution` argument to `compile` in\n",
            " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
            " |      batches.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch: Integer, index of batch within the current epoch.\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_predict_batch_end(self, batch, logs=None)\n",
            " |      Called at the end of a batch in `predict` methods.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Note that if the `steps_per_execution` argument to `compile` in\n",
            " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
            " |      batches.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch: Integer, index of batch within the current epoch.\n",
            " |          logs: Dict. Aggregated metric results up until this batch.\n",
            " |  \n",
            " |  on_predict_begin(self, logs=None)\n",
            " |      Called at the beginning of prediction.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Args:\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_predict_end(self, logs=None)\n",
            " |      Called at the end of prediction.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Args:\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_test_batch_begin(self, batch, logs=None)\n",
            " |      Called at the beginning of a batch in `evaluate` methods.\n",
            " |      \n",
            " |      Also called at the beginning of a validation batch in the `fit`\n",
            " |      methods, if validation data is provided.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Note that if the `steps_per_execution` argument to `compile` in\n",
            " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
            " |      batches.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch: Integer, index of batch within the current epoch.\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_test_batch_end(self, batch, logs=None)\n",
            " |      Called at the end of a batch in `evaluate` methods.\n",
            " |      \n",
            " |      Also called at the end of a validation batch in the `fit`\n",
            " |      methods, if validation data is provided.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Note that if the `steps_per_execution` argument to `compile` in\n",
            " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
            " |      batches.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch: Integer, index of batch within the current epoch.\n",
            " |          logs: Dict. Aggregated metric results up until this batch.\n",
            " |  \n",
            " |  on_test_begin(self, logs=None)\n",
            " |      Called at the beginning of evaluation or validation.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Args:\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_test_end(self, logs=None)\n",
            " |      Called at the end of evaluation or validation.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Args:\n",
            " |          logs: Dict. Currently the output of the last call to\n",
            " |            `on_test_batch_end()` is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_train_batch_begin(self, batch, logs=None)\n",
            " |      Called at the beginning of a training batch in `fit` methods.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Note that if the `steps_per_execution` argument to `compile` in\n",
            " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
            " |      batches.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch: Integer, index of batch within the current epoch.\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_train_batch_end(self, batch, logs=None)\n",
            " |      Called at the end of a training batch in `fit` methods.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Note that if the `steps_per_execution` argument to `compile` in\n",
            " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
            " |      batches.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch: Integer, index of batch within the current epoch.\n",
            " |          logs: Dict. Aggregated metric results up until this batch.\n",
            " |  \n",
            " |  set_model(self, model)\n",
            " |  \n",
            " |  set_params(self, params)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from Callback:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(EarlyStopping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GihCHZ3toRvS"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(monitor = 'val_loss' , mode = 'min' , verbose =1 , patience = 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pG82qIKoh0A",
        "outputId": "248eb8e4-3602-45b3-d7ed-9a5b9d4a35e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "14/14 [==============================] - 1s 14ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/600\n",
            "14/14 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f22dc550190>"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train , y_train , epochs = 600 , validation_data = (X_test , y_test) , callbacks = [early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "qIXyrN7irB6M",
        "outputId": "39f0497c-3911-4391-fb6f-637a2f65234a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f22dc3d0810>"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "losses.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGNiWCTlrHOO"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(30,activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(15,activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy' , optimizer = 'adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4AH0H2ftfdb",
        "outputId": "ea06f6c5-0819-4945-ba79-bf004891a72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "14/14 [==============================] - 1s 16ms/step - loss: 0.7014 - val_loss: 0.6749\n",
            "Epoch 2/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6819 - val_loss: 0.6630\n",
            "Epoch 3/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6670 - val_loss: 0.6493\n",
            "Epoch 4/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6550 - val_loss: 0.6354\n",
            "Epoch 5/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6405 - val_loss: 0.6157\n",
            "Epoch 6/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6196 - val_loss: 0.5872\n",
            "Epoch 7/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6025 - val_loss: 0.5636\n",
            "Epoch 8/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.5801 - val_loss: 0.5416\n",
            "Epoch 9/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.5540 - val_loss: 0.5082\n",
            "Epoch 10/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5403 - val_loss: 0.4759\n",
            "Epoch 11/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5107 - val_loss: 0.4446\n",
            "Epoch 12/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.5129 - val_loss: 0.4191\n",
            "Epoch 13/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4458 - val_loss: 0.3979\n",
            "Epoch 14/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4624 - val_loss: 0.3733\n",
            "Epoch 15/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4311 - val_loss: 0.3541\n",
            "Epoch 16/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4156 - val_loss: 0.3270\n",
            "Epoch 17/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4051 - val_loss: 0.3055\n",
            "Epoch 18/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3798 - val_loss: 0.2856\n",
            "Epoch 19/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3711 - val_loss: 0.2716\n",
            "Epoch 20/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3832 - val_loss: 0.2593\n",
            "Epoch 21/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3632 - val_loss: 0.2442\n",
            "Epoch 22/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3340 - val_loss: 0.2322\n",
            "Epoch 23/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3150 - val_loss: 0.2158\n",
            "Epoch 24/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2942 - val_loss: 0.2241\n",
            "Epoch 25/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3025 - val_loss: 0.1953\n",
            "Epoch 26/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3114 - val_loss: 0.1913\n",
            "Epoch 27/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2665 - val_loss: 0.1843\n",
            "Epoch 28/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2557 - val_loss: 0.1750\n",
            "Epoch 29/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2630 - val_loss: 0.1663\n",
            "Epoch 30/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2475 - val_loss: 0.1578\n",
            "Epoch 31/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2725 - val_loss: 0.1580\n",
            "Epoch 32/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2640 - val_loss: 0.1608\n",
            "Epoch 33/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2681 - val_loss: 0.1517\n",
            "Epoch 34/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2593 - val_loss: 0.1494\n",
            "Epoch 35/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2234 - val_loss: 0.1433\n",
            "Epoch 36/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2325 - val_loss: 0.1400\n",
            "Epoch 37/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2205 - val_loss: 0.1435\n",
            "Epoch 38/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2326 - val_loss: 0.1397\n",
            "Epoch 39/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2219 - val_loss: 0.1333\n",
            "Epoch 40/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1992 - val_loss: 0.1273\n",
            "Epoch 41/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1996 - val_loss: 0.1311\n",
            "Epoch 42/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2150 - val_loss: 0.1245\n",
            "Epoch 43/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2088 - val_loss: 0.1232\n",
            "Epoch 44/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2073 - val_loss: 0.1260\n",
            "Epoch 45/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1867 - val_loss: 0.1280\n",
            "Epoch 46/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1752 - val_loss: 0.1211\n",
            "Epoch 47/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1767 - val_loss: 0.1214\n",
            "Epoch 48/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1619 - val_loss: 0.1207\n",
            "Epoch 49/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1787 - val_loss: 0.1150\n",
            "Epoch 50/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1700 - val_loss: 0.1280\n",
            "Epoch 51/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1868 - val_loss: 0.1119\n",
            "Epoch 52/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1672 - val_loss: 0.1212\n",
            "Epoch 53/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1755 - val_loss: 0.1143\n",
            "Epoch 54/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1615 - val_loss: 0.1084\n",
            "Epoch 55/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1727 - val_loss: 0.1088\n",
            "Epoch 56/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1661 - val_loss: 0.1179\n",
            "Epoch 57/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1741 - val_loss: 0.1116\n",
            "Epoch 58/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1697 - val_loss: 0.1101\n",
            "Epoch 59/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1590 - val_loss: 0.1102\n",
            "Epoch 60/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1408 - val_loss: 0.1119\n",
            "Epoch 61/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1587 - val_loss: 0.1151\n",
            "Epoch 62/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1426 - val_loss: 0.1054\n",
            "Epoch 63/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1403 - val_loss: 0.1037\n",
            "Epoch 64/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1394 - val_loss: 0.1116\n",
            "Epoch 65/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1689 - val_loss: 0.1045\n",
            "Epoch 66/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1449 - val_loss: 0.1106\n",
            "Epoch 67/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1586 - val_loss: 0.1126\n",
            "Epoch 68/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1455 - val_loss: 0.1081\n",
            "Epoch 69/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1450 - val_loss: 0.1165\n",
            "Epoch 70/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1352 - val_loss: 0.1073\n",
            "Epoch 71/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1585 - val_loss: 0.1056\n",
            "Epoch 72/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1502 - val_loss: 0.1128\n",
            "Epoch 73/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1332 - val_loss: 0.1075\n",
            "Epoch 74/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1252 - val_loss: 0.1025\n",
            "Epoch 75/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1146 - val_loss: 0.1070\n",
            "Epoch 76/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1408 - val_loss: 0.1060\n",
            "Epoch 77/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1364 - val_loss: 0.1034\n",
            "Epoch 78/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1240 - val_loss: 0.1143\n",
            "Epoch 79/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1374 - val_loss: 0.1076\n",
            "Epoch 80/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1041 - val_loss: 0.1108\n",
            "Epoch 81/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1303 - val_loss: 0.1033\n",
            "Epoch 82/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1114 - val_loss: 0.1093\n",
            "Epoch 83/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1276 - val_loss: 0.1191\n",
            "Epoch 84/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1135 - val_loss: 0.1118\n",
            "Epoch 85/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1058 - val_loss: 0.1037\n",
            "Epoch 86/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1132 - val_loss: 0.1045\n",
            "Epoch 87/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1186 - val_loss: 0.1017\n",
            "Epoch 88/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1115 - val_loss: 0.1147\n",
            "Epoch 89/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1023 - val_loss: 0.1068\n",
            "Epoch 90/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1189 - val_loss: 0.1017\n",
            "Epoch 91/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1070 - val_loss: 0.1079\n",
            "Epoch 92/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1252 - val_loss: 0.1108\n",
            "Epoch 93/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1333 - val_loss: 0.1063\n",
            "Epoch 94/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1047 - val_loss: 0.1126\n",
            "Epoch 95/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1137 - val_loss: 0.1127\n",
            "Epoch 96/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1037 - val_loss: 0.1020\n",
            "Epoch 97/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1134 - val_loss: 0.1055\n",
            "Epoch 98/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1319 - val_loss: 0.1076\n",
            "Epoch 99/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1048 - val_loss: 0.1046\n",
            "Epoch 100/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1090 - val_loss: 0.0995\n",
            "Epoch 101/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0916 - val_loss: 0.1104\n",
            "Epoch 102/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0993 - val_loss: 0.1185\n",
            "Epoch 103/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0896 - val_loss: 0.1019\n",
            "Epoch 104/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1072 - val_loss: 0.1049\n",
            "Epoch 105/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1272 - val_loss: 0.1154\n",
            "Epoch 106/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1005 - val_loss: 0.1250\n",
            "Epoch 107/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1092 - val_loss: 0.1152\n",
            "Epoch 108/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0956 - val_loss: 0.1160\n",
            "Epoch 109/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1119 - val_loss: 0.1122\n",
            "Epoch 110/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0991 - val_loss: 0.1166\n",
            "Epoch 111/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0972 - val_loss: 0.1087\n",
            "Epoch 112/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0999\n",
            "Epoch 113/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1167 - val_loss: 0.1176\n",
            "Epoch 114/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1209 - val_loss: 0.1077\n",
            "Epoch 115/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.1007\n",
            "Epoch 116/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0929 - val_loss: 0.1161\n",
            "Epoch 117/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0926 - val_loss: 0.1112\n",
            "Epoch 118/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1129 - val_loss: 0.1048\n",
            "Epoch 119/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0982 - val_loss: 0.1105\n",
            "Epoch 120/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0810 - val_loss: 0.1382\n",
            "Epoch 121/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1079 - val_loss: 0.0959\n",
            "Epoch 122/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0979 - val_loss: 0.1027\n",
            "Epoch 123/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0886 - val_loss: 0.1103\n",
            "Epoch 124/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0836 - val_loss: 0.1246\n",
            "Epoch 125/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.1159\n",
            "Epoch 126/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.1012\n",
            "Epoch 127/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0933 - val_loss: 0.1092\n",
            "Epoch 128/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.1147\n",
            "Epoch 129/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0844 - val_loss: 0.1166\n",
            "Epoch 130/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0957 - val_loss: 0.1119\n",
            "Epoch 131/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0962 - val_loss: 0.1172\n",
            "Epoch 132/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0849 - val_loss: 0.1039\n",
            "Epoch 133/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0911 - val_loss: 0.1032\n",
            "Epoch 134/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0961 - val_loss: 0.1043\n",
            "Epoch 135/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1057 - val_loss: 0.1158\n",
            "Epoch 136/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0818 - val_loss: 0.1179\n",
            "Epoch 137/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0985 - val_loss: 0.1074\n",
            "Epoch 138/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0980 - val_loss: 0.1222\n",
            "Epoch 139/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1089 - val_loss: 0.1053\n",
            "Epoch 140/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0895 - val_loss: 0.1076\n",
            "Epoch 141/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0842 - val_loss: 0.1186\n",
            "Epoch 142/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0940 - val_loss: 0.1129\n",
            "Epoch 143/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.1085\n",
            "Epoch 144/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0915 - val_loss: 0.1289\n",
            "Epoch 145/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0797 - val_loss: 0.1281\n",
            "Epoch 146/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0920 - val_loss: 0.1129\n",
            "Epoch 146: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd725906a50>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train , y_train , epochs = 600 , validation_data = (X_test , y_test) , callbacks = [early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "IA-5MfagtjvG",
        "outputId": "7631a907-8f26-41f8-91d2-c597bad9eb72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd7201f73d0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "losses.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_KjcMYFxLSQ"
      },
      "outputs": [],
      "source": [
        "y_predict = (model.predict(X_test) > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi6Qrktctvtc"
      },
      "outputs": [],
      "source": [
        "# or\n",
        "\n",
        "y_predict = np.round(model.predict(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G668OqSPyOnh",
        "outputId": "2403840f-00d9-4e99-e258-30b23412ee06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egGvCTjuyHYB",
        "outputId": "6aa7ad40-4e94-4cd8-d1c3-6698c98e1691"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7y-rMg8xtEs"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report , confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEB6W5lKx4nO",
        "outputId": "e89b7ccb-9997-4c6e-853d-1dce8218e76b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98        88\n",
            "           1       0.95      0.98      0.96        55\n",
            "\n",
            "    accuracy                           0.97       143\n",
            "   macro avg       0.97      0.97      0.97       143\n",
            "weighted avg       0.97      0.97      0.97       143\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_predict))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('tensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ee7d7838ef53998fd22ad7449b76e48b4013ea11e59d28ee193f2cd757746339"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
